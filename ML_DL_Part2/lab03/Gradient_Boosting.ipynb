{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbpB6X8PAenmwexKuFDNuM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NguyenTien-beep/DAP391m/blob/main/ML_DL_Part2/lab03/Gradient_Boosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wRejTSGXbUAh"
      },
      "outputs": [],
      "source": [
        "#survivors on Titanic\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "train_data = pd.read_csv(\"/content/train.csv\")\n",
        "test_data = pd.read_csv(\"/content/test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare data"
      ],
      "metadata": {
        "id": "PQ4cWKRrcA3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create output vector\n",
        "y_train = train_data[\"Survived\"]\n",
        "train_data.drop(labels=\"Survived\", axis=1, inplace=True)\n",
        "\n",
        "#prepare data\n",
        "full_data = pd.concat([train_data, test_data], axis=0)\n",
        "\n",
        "#remove unnecessary columns\n",
        "drop_columns = [\"Name\", \"Age\", \"SibSp\", \"Ticket\", \"Cabin\", \"Parch\", \"Embarked\"]\n",
        "full_data.drop(labels=drop_columns, axis=1, inplace=True)\n",
        "\n",
        "full_data = pd.get_dummies(full_data, columns=[\"Sex\"])\n",
        "full_data.fillna(value=0.0, inplace=True)\n",
        "\n",
        "X_train = full_data.values[0:891]\n",
        "X_test = full_data.values[891:]\n",
        "\n",
        "# scale date\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#Divide into training and validation data\n",
        "\n",
        "state = 12\n",
        "test_size = 0.30\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=test_size, random_state=state)"
      ],
      "metadata": {
        "id": "x071A1bTbriR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build Gradient Boosting classifier - learning rate optimization\n",
        "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
        "\n",
        "for learning_rate in lr_list:\n",
        "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
        "    gb_clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Learning rate: \", learning_rate)\n",
        "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
        "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_val, y_val)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6oCzKdtcC6Q",
        "outputId": "0d488160-d027-41ce-bfad-7dad4749ec34"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  0.05\n",
            "Accuracy score (training): 0.801\n",
            "Accuracy score (validation): 0.731\n",
            "Learning rate:  0.075\n",
            "Accuracy score (training): 0.814\n",
            "Accuracy score (validation): 0.731\n",
            "Learning rate:  0.1\n",
            "Accuracy score (training): 0.812\n",
            "Accuracy score (validation): 0.724\n",
            "Learning rate:  0.25\n",
            "Accuracy score (training): 0.835\n",
            "Accuracy score (validation): 0.750\n",
            "Learning rate:  0.5\n",
            "Accuracy score (training): 0.864\n",
            "Accuracy score (validation): 0.772\n",
            "Learning rate:  0.75\n",
            "Accuracy score (training): 0.875\n",
            "Accuracy score (validation): 0.754\n",
            "Learning rate:  1\n",
            "Accuracy score (training): 0.875\n",
            "Accuracy score (validation): 0.739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The findings show that a higher learning rate isn't necessarily preferable. Validation accuracy peaks at a learning rate of 0.5 and subsequently starts to deteriorate, suggesting overfitting and worse generalization for higher learning rates, even though increasing the learning rate increases training accuracy.\n"
      ],
      "metadata": {
        "id": "-mJqbAPPdRP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate predictions"
      ],
      "metadata": {
        "id": "jh5QYo5Mcm72"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use GRB model where learning_rate=0,5 to generate predictions\n",
        "gb_clf2 = GradientBoostingClassifier(n_estimators=20, learning_rate=0.5, max_features=2, max_depth=2, random_state=0)\n",
        "gb_clf2.fit(X_train, y_train)\n",
        "predictions = gb_clf2.predict(X_val)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, predictions))\n",
        "\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_val, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82UxfOVTdVN2",
        "outputId": "1d632349-8b79-435b-8b07-8d1621a844a4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[142  19]\n",
            " [ 42  65]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.88      0.82       161\n",
            "           1       0.77      0.61      0.68       107\n",
            "\n",
            "    accuracy                           0.77       268\n",
            "   macro avg       0.77      0.74      0.75       268\n",
            "weighted avg       0.77      0.77      0.77       268\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Toy example 1b (XGBoost)"
      ],
      "metadata": {
        "id": "qSe0PkVndWZa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#survivors on Titanic\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_clf = XGBClassifier()\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "score = xgb_clf.score(X_val, y_val)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq3gGrU7dZV0",
        "outputId": "40c3ba0e-4a76-433d-83f4-71c1ea70494b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7313432835820896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# load data\n",
        "dataset = loadtxt('/content/diabetes.csv', delimiter=\",\")\n",
        "# split data into X and y\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# CV model\n",
        "model = XGBClassifier()\n",
        "kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WOKn8Xrdb2z",
        "outputId": "a1da5a64-9b7e-49b9-a6b8-16f5a43b8dcf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 73.97% (5.53%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# load data\n",
        "dataset = loadtxt('diabetes.csv', delimiter=\",\")\n",
        "# split data into X and y\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# CV model\n",
        "model = XGBClassifier()\n",
        "kfold = StratifiedKFold(n_splits=10, random_state=7,shuffle=True)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgy_SOPmdeo2",
        "outputId": "cfe14ef0-6318-463b-df1d-73e65ddba6de"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 73.43% (4.47%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KOiRvVgwemf-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}